{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Polars: Faster than Pandas <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install polars\n",
    "import polars as pl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "from datetime import*\n",
    "timedf = pl.DataFrame(\n",
    "    {\n",
    "        \"Interger\" : [1,2,3],\n",
    "        \"Name\": ['Linh','Binh','Thu'],\n",
    "        'Date': [\n",
    "                datetime(2004,3,20),\n",
    "                datetime(2007,2,18),\n",
    "                datetime(2005,11,29)\n",
    "        ],\n",
    "        'Mark': [6,7,8]\n",
    "    }\n",
    ")\n",
    "timedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file csv\n",
    "df = pl.read_csv(\"./apple_quality.csv\",ignore_errors = True,has_header=True)\n",
    "# Read file parquet\n",
    "pq = pl.read_parquet(\"./exam.parquet\",columns=['Name','Mark'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Expression :<h1> \n",
    " select, filter, with_columns, group_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  SELECT:\n",
    "# 1. Define the DataFrame we want the data from.\n",
    "# 2. Select the data that we need.\n",
    "df.select(pl.col(\"*\"))\n",
    "df.select(['Size','Weight'])\n",
    "\n",
    "# Select first and last row\n",
    "df.head(2)\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample\n",
    "\n",
    "# Take a random sample\n",
    "df.sample(5)\n",
    "\n",
    "# Randomly select fraction of rows. \n",
    "df.sample(fraction=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILTER:\n",
    "# use to create subset\n",
    "# Filter: Extract rows that meet logical criteria\n",
    "df.filter(pl.col(\"Weight\")>=5)\n",
    "df.filter((pl.col(\"Weight\")>4) & (pl.col(\"Quality\")=='good'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GROUP BY\n",
    "df2 = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n",
    "        \"b\": [1, 2, 1, 3, 3],\n",
    "        \"c\": [5, 4, 3, 2, 1],\n",
    "    }\n",
    ")\n",
    "df2.group_by(\"a\",maintain_order=True).len()\n",
    "df2.group_by(\"a\",maintain_order=True).agg(pl.col('b').sum().alias(\"Total_B\"),pl.col(\"c\").mean().alias(\"AVG_C\"))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WITH COLUMNS\n",
    "# Adding new column\n",
    "# Create a new column and get in a new variable\n",
    "df3=df2.with_columns((pl.col('c')*2).alias(\"C x 2\"))\n",
    "\n",
    "# Create several columns\n",
    "df4=df3.with_columns(\n",
    "    [\n",
    "    ((pl.col('b')+pl.col('C x 2')).alias('b+Cx2')),\n",
    "    (pl.col('b').mean().alias(\"Mean of b\"))\n",
    "    ]\n",
    ")\n",
    "df4\n",
    "\n",
    "# Add a column to indexed the row\n",
    "df4.with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SORT DATA\n",
    "sorted_data = df.sort(['Weight','Crunchiness'],descending=[True,False])\n",
    "sorted_data\n",
    "df.filter(df['Weight'].is_unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HANDLING MISSING DATA\n",
    "\n",
    "# drop null rows\n",
    "df.drop_nulls()\n",
    "# Replace null with a value\n",
    "df.fill_null(5555)\n",
    "# Other ll strategies are \"backward\", \"min\", \"max\", \"mean\", \"zero\" and \"one\"\n",
    "df.fill_null(strategy='zero')\n",
    "\n",
    "# Filling NaN by given value (NaN: Not a Number)\n",
    "df.fill_nan(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Reshaping data, CONCAT, MERGING TABLE, COLUMNS <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging DataFrames Combining multiple DataFrames\n",
    "dff = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [1, 2, 3],\n",
    "        \"bar\": [6, 7, 8],\n",
    "        \"ham\": [\"a\", \"b\", \"c\"],\n",
    "    }\n",
    ")\n",
    "x = pl.Series(\"apple\", [10, 20, 30])\n",
    "print(dff.hstack([x]))\n",
    "\n",
    "\n",
    "dff1 = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [1, 2],\n",
    "        \"bar\": [6, 7],\n",
    "        \"ham\": [\"a\", \"b\"],\n",
    "    }\n",
    ")\n",
    "dff2 = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [3, 4],\n",
    "        \"bar\": [8, 9],\n",
    "        \"ham\": [\"c\", \"d\"],\n",
    "    }\n",
    ")\n",
    "print(dff1.vstack(dff2))\n",
    "dff2.select(pl.all().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Append columns of DataFrames\n",
    "pl.concat([dff,pl.DataFrame(x)],how = 'horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append rows of DataFrame\n",
    "pl.concat([dff1,dff2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Summarize Data <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n",
    "df.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of rows with each unique value of variable\n",
    "df['Quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of distinct values in a column\n",
    "df['Quality'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Join Table <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "df_join = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": range(8),\n",
    "        \"b\": np.random.rand(8),\n",
    "        \"d\": [1, 2.0, float(\"nan\"), float(\"nan\"), 0, -5, -42, None],\n",
    "    }\n",
    ")\n",
    "\n",
    "df_join2 = pl.DataFrame(\n",
    "    {\n",
    "        \"x\": range(8),\n",
    "        \"y\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"X\", \"X\"],\n",
    "    }\n",
    ")\n",
    "df_join3 = df_join.join(df_join2,left_on='a',right_on='x')\n",
    "df_join3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_join = pl.DataFrame(\n",
    "    {\n",
    "        \"foo\": [1, 2, 3],\n",
    "        \"bar\": [6.0, 7.0, 8.0],\n",
    "        \"ham\": [\"a\", \"b\", \"c\"],\n",
    "    }\n",
    ")\n",
    "other_join = pl.DataFrame(\n",
    "    {\n",
    "        \"apple\": [\"x\", \"y\", \"z\"],\n",
    "        \"ham\": [\"a\", \"b\", \"d\"],\n",
    "    }\n",
    ")\n",
    "join = d_join.join(other_join,on='ham',how = 'outer')\n",
    "join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "<h1> Truy vấn SQL dùng Polars <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctx = pl.SQLContext()\n",
    "pokemon_data = pl.read_csv(\"https://gist.githubusercontent.com/ritchie46/cac6b337ea52281aa23c049250a4ff03/raw/89a957ff3919d90e6ef2d34235e6bf22304f3366/pokemon.csv\")\n",
    "pokemon_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = pl.SQLContext(register_globals=True,eager_execution=False)\n",
    "poke_small = ctx.execute(\n",
    "    '''\n",
    "    select *\n",
    "    from pokemon_data\n",
    "    order by HP desc\n",
    "    where HP>115\n",
    "    \n",
    "    limit 3\n",
    "    '''\n",
    ")\n",
    "poke_small.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
